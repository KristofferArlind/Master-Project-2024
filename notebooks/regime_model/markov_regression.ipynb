{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_parquet(\"../../data/indicators/US/all_indicators_raw_outer.parquet\", engine=\"pyarrow\")\n",
    "indicators[\"date\"] = pd.to_datetime(indicators[\"date\"])\n",
    "indicators.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_recessions = pd.read_parquet(\"../../data/indicators/US/nber_recession.parquet\")\n",
    "nber_recessions[\"date\"] = pd.to_datetime(nber_recessions[\"date\"])\n",
    "nber_recessions = nber_recessions[nber_recessions[\"date\"] >= \"1962-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_top_500 = pd.read_parquet(\"../../data/indicators/US/us_top_500.parquet\", engine=\"pyarrow\")\n",
    "us_top_500[\"date\"] = pd.to_datetime(us_top_500[\"date\"])\n",
    "data = pd.merge(indicators, us_top_500, on=[\"date\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    print(column)\n",
    "    print(data[column].dropna().index.min())\n",
    "    print(data[column].dropna().index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ism_prod\"] = data[\"ISM_prod_index\"].copy()\n",
    "data[\"vix\"] = data[\"vix_SP500_close\"].copy()\n",
    "data[\"inflation\"] = data[\"inflation\"]/100\n",
    "data.loc[data.index < pd.Timestamp(\"1997-01-01\"), \"dvps_12m\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shifting appropriate date periods, daily data:\n",
    "data[\"vix\"] = data[\"vix\"].shift(1, freq = \"D\")\n",
    "data[\"market_cap_usd\"] = data[\"market_cap_usd\"].shift(1, freq = \"D\")\n",
    "data[\"credit_spread\"] = data[\"credit_spread\"].shift(1, freq = \"D\")\n",
    "data[\"rate_fed_funds\"] = data[\"rate_fed_funds\"].shift(1, freq = \"D\")\n",
    "data[\"rate_1_year\"] = data[\"rate_1_year\"].shift(1, freq = \"D\")\n",
    "data[\"rate_3_year\"] = data[\"rate_3_year\"].shift(1, freq = \"D\")\n",
    "data[\"rate_5_year\"] = data[\"rate_5_year\"].shift(1, freq = \"D\")\n",
    "data[\"rate_10_year\"] = data[\"rate_10_year\"].shift(1, freq = \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shifting appropriate date periods, weekly data:\n",
    "data[\"initial_claims\"] = data[\"initial_claims\"].dropna().shift(1, freq = \"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shifting appropriate date periods, monthly and quarterly data:\n",
    "data[\"real_gnp\"] = data[\"real_gnp\"].dropna().shift(3 + 2, freq = \"MS\")\n",
    "data[\"real_gdp\"] = data[\"real_gdp\"].dropna().shift(3 + 2, freq = \"MS\")\n",
    "data[\"M1\"] = data[\"M1\"].dropna().shift(1, freq = \"MS\")\n",
    "data[\"M2\"] = data[\"M2\"].dropna().shift(1, freq = \"MS\")\n",
    "data[\"ism_prod\"] = data[\"ism_prod\"].resample(\"ME\").mean().shift(1, freq=\"D\")\n",
    "data[\"pce\"] = data[\"pce\"].dropna().shift(1, freq = \"MS\").shift(7, freq = \"D\")\n",
    "data[\"unemployment\"] = data[\"unemployment\"].dropna().shift(2, freq = \"MS\")\n",
    "data[\"earnings_yield\"] = data[\"earnings_yield_12m\"].dropna().shift(-1, freq = \"D\").resample(\"QE\").last().shift(1, freq = \"D\").shift(2, freq=\"MS\")\n",
    "data[\"dividend_yield\"] = data[\"dividend_yield_12m\"].dropna().shift(0, freq = \"MS\")\n",
    "data[\"eps\"] = data[\"eps_12m\"].dropna().shift(-1, freq = \"D\").resample(\"QE\").last().shift(1, freq = \"D\").shift(2, freq=\"MS\")\n",
    "data[\"dvps\"] = data[\"dvps_12m\"].dropna().shift(0, freq = \"MS\")\n",
    "data[\"inflation\"] = data[\"inflation\"].dropna().shift(2, freq = \"MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is resampled to month-end and added one day to, so the first day of the month is information from last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily data, resample to monthly, pct_change\n",
    "data[\"vix_change\"] = data[\"vix\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"mc_change\"] = data[\"market_cap_usd\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"credit_spread_change\"] = data[\"credit_spread\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"rate_fed_funds_change\"] = data[\"rate_fed_funds\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"rate_1_year_change\"] = data[\"rate_1_year\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"rate_3_year_change\"] = data[\"rate_3_year\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"rate_5_year_change\"] = data[\"rate_5_year\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()\n",
    "data[\"rate_10_year_change\"] = data[\"rate_10_year\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekly data, resample to monthly, pct_change\n",
    "data[\"initial_claims_change\"] = data[\"initial_claims\"].resample(\"ME\").mean().shift(1, freq=\"D\").dropna().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly data, pct_change\n",
    "\n",
    "data[\"real_gnp_change\"] = data[\"real_gnp\"].dropna().pct_change()\n",
    "data[\"real_gdp_change\"] = data[\"real_gdp\"].dropna().pct_change()\n",
    "data[\"m1_change\"] = data[\"M1\"].dropna().pct_change()\n",
    "data[\"m2_change\"] = data[\"M2\"].dropna().pct_change()\n",
    "data[\"ism_prod_change\"] = data[\"ism_prod\"].dropna().pct_change()\n",
    "data[\"pce_change\"] = data[\"pce\"].dropna().pct_change()\n",
    "data[\"unemployment_change\"] = data[\"unemployment\"].dropna().pct_change()\n",
    "data[\"earnings_yield_change\"] = data[\"earnings_yield\"].dropna().pct_change()\n",
    "data[\"dividend_yield_change\"] = data[\"dividend_yield\"].dropna().pct_change()\n",
    "data[\"eps_change\"] = data[\"eps\"].dropna().pct_change()\n",
    "data[\"dvps_change\"] = data[\"dvps\"].dropna().pct_change()\n",
    "data[\"inflation_change\"] = data[\"inflation\"].dropna().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def save_data(data, feature, train_suffix, test_suffix = None, first_test_date = None, winsorize_std = 3, winsorize_quantile=None, scale_data=False, log_transform=False):\n",
    "    assert(train_suffix is not None)\n",
    "    assert(not (winsorize_std and winsorize_quantile))\n",
    "    \n",
    "    data_train = data[[feature]].copy().dropna()\n",
    "    print(data_train.head())\n",
    "\n",
    "    if winsorize_quantile is not None:\n",
    "        data_train[feature] = data_train[feature].clip(lower = data_train[feature].quantile(winsorize_quantile), upper = data_train[feature].quantile(1-winsorize_quantile))\n",
    "\n",
    "    if winsorize_std is not None:\n",
    "        train_std = data_train[feature].std()\n",
    "        data_train[feature] = data_train[feature].clip(lower = -train_std*winsorize_std, upper = train_std*winsorize_std)\n",
    "        data_test[feature] = data_test[feature].clip(lower = -train_std*winsorize_std, upper = train_std*winsorize_std)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    if first_test_date is not None:\n",
    "        data_test = data_train[data_train.index >= first_test_date]\n",
    "        data_train = data_train[data_train.index < first_test_date]\n",
    "\n",
    "    if data_train.shape[0] == 0:\n",
    "        print(\"No data for feature after test date, saving empty dataframe\")\n",
    "        pd.DataFrame(data_train).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_train_{train_suffix}.csv\")\n",
    "        if first_test_date is not None:\n",
    "            pd.DataFrame(data_test).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_test_{test_suffix}.csv\")\n",
    "            data_all = pd.concat([data_train, data_test])\n",
    "            pd.DataFrame(data_all).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_all_{train_suffix}.csv\")\n",
    "\n",
    "        return\n",
    "\n",
    "    if log_transform:\n",
    "        if (data_train[feature].min() + 1) <= 0:\n",
    "            print(data_train[feature].min())\n",
    "            print(f\"Feature {feature} has too negative values, cannot log transform\")\n",
    "            return\n",
    "        data_train[feature] = np.log(1 + data_train[feature])\n",
    "        if first_test_date is not None:\n",
    "            data_test[feature] = np.log(1 + data_test[feature])\n",
    "\n",
    "    if scale_data:\n",
    "        data_train[feature] = scaler.fit_transform(data_train[feature].values.reshape(-1, 1))\n",
    "        if first_test_date is not None:\n",
    "            data_test[feature] = scaler.transform(data_test[feature].values.reshape(-1, 1))\n",
    "\n",
    "    print(feature)\n",
    "    if first_test_date is not None:\n",
    "        data_all = pd.concat([data_train, data_test])\n",
    "        data_all[feature].plot()\n",
    "    else:\n",
    "        data_train[feature].plot()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    pd.DataFrame(data_train).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_train_{train_suffix}.csv\")\n",
    "    if first_test_date is not None:\n",
    "        pd.DataFrame(data_test).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_test_{test_suffix}.csv\")\n",
    "        \n",
    "        pd.DataFrame(data_all).to_csv(f\"../../data/indicators/US/matlab_ready/{feature}_all_{train_suffix}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is processed and saved to be used in the matlab script to fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only change variables:\n",
    "features_to_save = [\"vix_change\", \"mc_change\", \"credit_spread_change\",\n",
    "                    \"rate_fed_funds_change\",\n",
    "                    \"rate_1_year_change\", \"rate_3_year_change\", \"rate_5_year_change\", \"rate_10_year_change\", \n",
    "                    \"initial_claims_change\", \n",
    "                    \"real_gnp_change\", \"real_gdp_change\", \"m1_change\", \"m2_change\", \n",
    "                    \"ism_prod_change\", \"pce_change\", \"unemployment_change\",\n",
    "                    \"earnings_yield_change\", \"dividend_yield_change\", \n",
    "                    #\"inflation_change\"\n",
    "                    \"inflation\",\n",
    "                    \"dvps_change\", \"eps_change\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "data_copy.index = pd.to_datetime(data_copy.index)\n",
    "\n",
    "year_to_save = 2020\n",
    "\n",
    "train_suffix = f\"scale_win3std_log_{year_to_save}\"\n",
    "test_suffix = f\"scale_win3std_log_{year_to_save}\"\n",
    "\n",
    "first_test_date = pd.Timestamp(f\"{year_to_save}-01-01\")\n",
    "\n",
    "for feature in features_to_save:\n",
    "    save_data(data_copy, feature, train_suffix, test_suffix, first_test_date, winsorize_std=3, winsorize_quantile=None, scale_data=True, log_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog_variables = [\n",
    "                \"mc_change\", \n",
    "                \"inflation\",\n",
    "                #\"inflation_change\",\n",
    "                #\"unemployment\", \n",
    "                \"unemployment_change\", \n",
    "                #\"rate_fed_funds\",\n",
    "                \"rate_fed_funds_change\", \n",
    "                \"initial_claims_change\",\n",
    "                #\"ism_prod_index\",\n",
    "                \"ism_prod_change\",\n",
    "                #\"real_gnp_change\", \n",
    "                #\"real_gdp_change\", \n",
    "                \"m1_change\", \n",
    "                \"m2_change\", \n",
    "                #\"rate_1_year\",\n",
    "                #\"rate_3_year\",\n",
    "                #\"rate_5_year\",\n",
    "                #\"rate_10_year\",\n",
    "                \"rate_1_year_change\",\n",
    "                #\"rate_3_year_change\",\n",
    "                #\"rate_5_year_change\",\n",
    "                \"rate_10_year_change\",\n",
    "                #\"earnings_yield\",\n",
    "                \"eps_change\",\n",
    "                #\"dvps_change\",\n",
    "                \"earnings_yield_change\",\n",
    "                #\"dividend_yield_change\",\n",
    "                #\"credit_spread\",\n",
    "                \"credit_spread_change\",\n",
    "                #\"pce_change\",\n",
    "                \"vix_change\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "prefix = \"train\"\n",
    "\n",
    "suffix = \"_smooth\"\n",
    "\n",
    "#suffix = \"_train_1990\"\n",
    "#suffix = \"_all_win_scaled_order4\"\n",
    "suffix = f\"_test_scale_win3std_log_{year}_order4_smooth\"\n",
    "\n",
    "suffixes = [f\"_{prefix}_scale_win3std_log_{year}_order1{suffix}\", f\"_{prefix}_scale_win3std_log_{year}_order4{suffix}\", f\"_{prefix}_scale_win3std_log_{year}_order10{suffix}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_date = pd.Timestamp(f\"{year}-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results are here imported from the directory where MATLAB saved them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results from matlab:\n",
    "all_probabilities = pd.DataFrame(columns=[\"endog\", \"order\", \"date\", \"p\"])\n",
    "\n",
    "for current_endog in endog_variables:\n",
    "    print(current_endog)\n",
    "    for suffix in suffixes:\n",
    "        current_results = pd.read_csv(\"../../results/regime/markov_matlab/\" + current_endog + suffix + \".csv\")\n",
    "        current_results[\"date\"] = pd.to_datetime(current_results[\"date\"], format=\"mixed\")\n",
    "        current_results[\"order\"] = int(suffix.split(\"order\")[1])\n",
    "        current_results[\"endog\"] = current_endog\n",
    "\n",
    "        all_probabilities = pd.concat([all_probabilities, current_results], axis=0)\n",
    "\n",
    "all_probabilities[\"date\"] = pd.to_datetime(all_probabilities[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect all probabilities from the test results into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_years = list(range(1980,2020+1,5))\n",
    "orders = [1,4,10]\n",
    "prefix = \"all\"\n",
    "flip_probs = False\n",
    "\n",
    "\n",
    "for year_i, year in enumerate(split_years):\n",
    "    for endog_i, current_endog in enumerate(endog_variables):\n",
    "        print(year, current_endog)\n",
    "        found_file = False\n",
    "        for order_i, order in enumerate(orders):\n",
    "            if not os.path.exists(\"../../results/regime/markov_matlab/\" + current_endog + f\"_{prefix}_scale_win3std_log_{year}_order{order}\" + \".csv\"):\n",
    "                print(year, current_endog, order, \" does not exist\")\n",
    "                continue\n",
    "            found_file = True\n",
    "\n",
    "            current_results = pd.read_csv(\"../../results/regime/markov_matlab/\" + current_endog + f\"_{prefix}_scale_win3std_log_{year}_order{order}\" + \".csv\")\n",
    "            current_results[\"date\"] = pd.to_datetime(current_results[\"date\"], format=\"mixed\")\n",
    "            current_results[\"endog\"] = current_endog\n",
    "            if order_i == 0:\n",
    "                avg_results = current_results\n",
    "                continue\n",
    "            current_results_train = current_results[current_results[\"date\"] < pd.Timestamp(f\"{year}-01-01\")]\n",
    "            avg_results_train = avg_results[avg_results[\"date\"] < train_test_split_date]\n",
    "            if flip_probs:\n",
    "                if ((current_results_train[\"p\"].mean() > 0.5) and (avg_results_train[\"p\"].mean() < 0.5)) or ((current_results_train[\"p\"].mean() < 0.5) and (avg_results_train[\"p\"].mean() > 0.5)):\n",
    "                    print(\"Flipping\", current_endog, suffix)\n",
    "                    current_results[\"p\"] = 1 - current_results[\"p\"]\n",
    "                    \n",
    "            avg_results = pd.concat([avg_results, current_results])\n",
    "        if not found_file:\n",
    "            continue\n",
    "            \n",
    "        avg_results = avg_results.groupby([\"endog\", \"date\"]).mean().reset_index()\n",
    "        avg_results[\"split_date\"] = pd.Timestamp(f\"{year}-01-01\")\n",
    "        if year != split_years[0]:\n",
    "            avg_results = avg_results[avg_results[\"date\"] >= pd.Timestamp(f\"{year}-01-01\")]\n",
    "        if year != split_years[-1]:\n",
    "            avg_results = avg_results[avg_results[\"date\"] < (pd.Timestamp(f\"{year}-01-01\") + pd.DateOffset(years=5))]\n",
    "                \n",
    "        if year_i == 0 and endog_i == 0:\n",
    "            test_probabilites = avg_results\n",
    "        else:\n",
    "            test_probabilites = pd.concat([test_probabilites, avg_results])\n",
    "            \n",
    "\n",
    "test_probabilites.sort_values([\"date\", \"endog\"], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilites.to_csv(\"../../results/regime/markov_collected/probabilities_scale_win3std_log_test_all_years_order1_4_10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get smoothed in-sample probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results from matlab:\n",
    "\n",
    "flip_probs = False\n",
    "\n",
    "probabilities = pd.DataFrame(columns=[\"endog\", \"date\", \"p\"])\n",
    "\n",
    "for current_endog in endog_variables:\n",
    "    print(current_endog)\n",
    "    avg_results = pd.DataFrame(columns=[\"endog\", \"date\", \"p\"])\n",
    "    for suffix in suffixes:\n",
    "        current_results = pd.read_csv(\"../../results/regime/markov_matlab/\" + current_endog + suffix + \".csv\")\n",
    "        current_results[\"date\"] = pd.to_datetime(current_results[\"date\"], format=\"mixed\")\n",
    "        current_results_train = current_results[current_results[\"date\"] < train_test_split_date]\n",
    "        avg_results_train = avg_results[avg_results[\"date\"] < train_test_split_date]\n",
    "        if flip_probs:\n",
    "            if ((current_results_train[\"p\"].mean() > 0.5) and (avg_results_train[\"p\"].mean() < 0.5)) or ((current_results_train[\"p\"].mean() < 0.5) and (avg_results_train[\"p\"].mean() > 0.5)):\n",
    "                print(\"Flipping\", current_endog, suffix)\n",
    "                current_results[\"p\"] = 1 - current_results[\"p\"]\n",
    "        current_results[\"endog\"] = current_endog\n",
    "        current_results[\"date\"] = pd.to_datetime(current_results[\"date\"])\n",
    "        avg_results = pd.concat([avg_results, current_results], axis=0)\n",
    "    avg_results = avg_results.groupby([\"endog\", \"date\"]).mean().reset_index()\n",
    "    \n",
    "    probabilities = pd.concat([probabilities, avg_results], axis=0)\n",
    "\n",
    "probabilities[\"date\"] = pd.to_datetime(probabilities[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog_variables_display = endog_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are imported after they are collected and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pd.read_csv(\"../../results/regime/markov_collected/probabilities_scale_win3std_log_train_2020_order1_4_10_smooth.csv\")\n",
    "probabilities[\"date\"] = pd.to_datetime(probabilities[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pd.read_csv(\"../../results/regime/markov_collected/probabilities_scale_win3std_log_test_all_years_order1_4_10.csv\")\n",
    "probabilities[\"date\"] = pd.to_datetime(probabilities[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endog in endog_variables_display:\n",
    "    print(endog)\n",
    "    print(probabilities[probabilities[\"endog\"] == endog].dropna()[\"date\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_rec_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_rec_dates[\"date\"] = pd.to_datetime(markov_rec_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_exp_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_exp_dates[\"date\"] = pd.to_datetime(markov_exp_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready/nber_recession_dates.csv\")\n",
    "nber_rec_dates[\"date\"] = pd.to_datetime(nber_rec_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(15, 8), sharex=False)\n",
    "\n",
    "ax = axes[0]\n",
    "\n",
    "expansion = False\n",
    "\n",
    "probabilities = probabilities.copy()\n",
    "\n",
    "\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "min_date = pd.Timestamp(\"1975-01-01\")\n",
    "\n",
    "flip_probs = False\n",
    "\n",
    "resample_freq = \"MS\"\n",
    "\n",
    "\n",
    "probabilities_display = probabilities[probabilities[\"date\"] > min_date]\n",
    "\n",
    "if expansion:\n",
    "    probabilities_display[\"p\"] = 1-probabilities_display[\"p\"]\n",
    "    \n",
    "\n",
    "if flip_probs:\n",
    "    for endog in endog_variables_display:\n",
    "        if probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"].mean() > 0.5:\n",
    "            print(endog, \" is flipped\")\n",
    "            probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"] = 1 - probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"]\n",
    "\n",
    "market_cap = data_copy[data_copy.index > probabilities_display[\"date\"].min()][\"market_cap_usd\"].resample(resample_freq).first()\n",
    "\n",
    "\n",
    "for current_endog in endog_variables_display:\n",
    "    print(current_endog)\n",
    "    print(probabilities_display[probabilities_display[\"endog\"] == current_endog].shape)\n",
    "    probabilities_display[probabilities_display[\"endog\"] == current_endog].plot(x=\"date\", y=\"p\", ax=ax)\n",
    "\n",
    "ax.axvline(pd.Timestamp(\"1980-01-01\"), color=\"black\", linestyle=\"--\", label=\"Fi\", linewidth=2)\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(nber_rec_dates['date'])-1):\n",
    "    if nber_rec_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == nber_rec_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(nber_rec_dates['date'].iloc[current_i], nber_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='grey', alpha=0.5)\n",
    "    current_i = i + 1\n",
    "\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "market_cap.plot(ax=ax2, alpha=0.5, color=\"tab:orange\", label=\"Index Market Cap (Log)\", logy=True, linewidth=2)\n",
    "\n",
    "avg_probabilities = probabilities_display[probabilities_display[\"endog\"].isin(endog_variables_display)].groupby(\"date\")[\"p\"].mean()\n",
    "avg_probabilities.plot(ax=ax, color=\"tab:blue\", label=\"average\", linewidth=2)\n",
    "\n",
    "axvlines = [pd.Timestamp(\"1980-01-01\"), pd.Timestamp(\"1985-01-01\"), pd.Timestamp(\"1990-01-01\"), \n",
    "                        pd.Timestamp(\"1995-01-01\"), pd.Timestamp(\"2000-01-01\"), pd.Timestamp(\"2005-01-01\"),\n",
    "                        pd.Timestamp(\"2010-01-01\"), pd.Timestamp(\"2015-01-01\"), pd.Timestamp(\"2020-01-01\")]\n",
    "\n",
    "for line in axvlines:\n",
    "    ax.axvline(line, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(nber_rec_dates['date'])-1):\n",
    "    if nber_rec_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == nber_rec_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(nber_rec_dates['date'].iloc[current_i], nber_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='grey', alpha=0.5)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(nber_rec_dates['date'].iloc[current_i], nber_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='grey', alpha=0.5)\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(markov_rec_dates['date'])-1):\n",
    "    if markov_rec_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == markov_rec_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(markov_rec_dates['date'].iloc[current_i], markov_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='red', alpha=0.3, ymin=0.5, ymax=0.9)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(markov_rec_dates['date'].iloc[current_i], markov_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='red', alpha=0.3, ymin=0.5, ymax=0.9)\n",
    "\n",
    "    \n",
    "current_i = 0\n",
    "for i in range(len(markov_exp_dates['date'])-1):\n",
    "    if markov_exp_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == markov_exp_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(markov_exp_dates['date'].iloc[current_i], markov_exp_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.5)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(markov_exp_dates['date'].iloc[current_i], markov_exp_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.5)\n",
    "\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "ax2.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "axes[0].axes.get_xaxis().set_label_text('')\n",
    "axes[1].axes.get_xaxis().set_label_text('')\n",
    "axes[0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "axes[1].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/markov_regression_smooth_2020.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_rec_filter_dates = pd.read_csv(\"../../time_periods/model_test_ready/markov_rec_dates_test_all_years_order1_4_10_5yr_avg.csv\")\n",
    "markov_rec_filter_dates[\"date\"] = pd.to_datetime(markov_rec_filter_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_exp_filter_dates = pd.read_csv(\"../../time_periods/model_test_ready/markov_exp_dates_test_all_years_order1_4_10_5yr_avg.csv\")\n",
    "markov_exp_filter_dates[\"date\"] = pd.to_datetime(markov_exp_filter_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilites = pd.read_csv(\"../../results/regime/markov_collected/probabilities_scale_win3std_log_test_all_years_order1_4_10.csv\")\n",
    "test_probabilites[\"date\"] = pd.to_datetime(test_probabilites[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only result plot\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12, 4), sharex=False)\n",
    "\n",
    "\n",
    "expansion = False\n",
    "\n",
    "#probabilities = test_probabilites.copy()\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "min_date = pd.Timestamp(\"1975-01-01\")\n",
    "\n",
    "flip_probs = False\n",
    "\n",
    "resample_freq = \"MS\"\n",
    "\n",
    "\n",
    "probabilities_display = probabilities[probabilities[\"date\"] > min_date]\n",
    "\n",
    "if expansion:\n",
    "    probabilities_display[\"p\"] = 1-probabilities_display[\"p\"]\n",
    "    \n",
    "\n",
    "if flip_probs:\n",
    "    for endog in endog_variables_display:\n",
    "        print(endog)\n",
    "        if probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"].mean() > 0.5:\n",
    "            print(endog, \" is flipped\")\n",
    "            probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"] = 1 - probabilities_display[probabilities_display[\"endog\"] == endog][\"p\"]\n",
    "\n",
    "market_cap = data_copy[data_copy.index > probabilities_display[\"date\"].min()][\"market_cap_usd\"].resample(resample_freq).first()\n",
    "\n",
    "\n",
    "\n",
    "avg_probabilities = probabilities_display[probabilities_display[\"endog\"].isin(endog_variables_display)].groupby(\"date\")[\"p\"].mean()\n",
    "avg_probabilities.plot(ax=ax, color=\"tab:blue\", label=\"average\", linewidth=2)\n",
    "\n",
    "axvlines = [pd.Timestamp(\"1980-01-01\"), pd.Timestamp(\"1985-01-01\"), pd.Timestamp(\"1990-01-01\"), \n",
    "                        pd.Timestamp(\"1995-01-01\"), pd.Timestamp(\"2000-01-01\"), pd.Timestamp(\"2005-01-01\"),\n",
    "                        pd.Timestamp(\"2010-01-01\"), pd.Timestamp(\"2015-01-01\"), pd.Timestamp(\"2020-01-01\")]\n",
    "\n",
    "for line in axvlines:\n",
    "    ax.axvline(line, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(nber_rec_dates['date'])-1):\n",
    "    if nber_rec_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == nber_rec_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(nber_rec_dates['date'].iloc[current_i], nber_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='grey', alpha=0.5)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(nber_rec_dates['date'].iloc[current_i], nber_rec_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='grey', alpha=0.5)\n",
    "\n",
    "\n",
    "current_negative_dates = markov_rec_dates\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(current_negative_dates['date'])-1):\n",
    "    if current_negative_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == current_negative_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(current_negative_dates['date'].iloc[current_i], current_negative_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='red', alpha=0.3, ymin=0.5, ymax=0.9)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(current_negative_dates['date'].iloc[current_i], current_negative_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='red', alpha=0.3, ymin=0.5, ymax=0.9)\n",
    "\n",
    "current_positive_dates = markov_exp_dates\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(current_positive_dates['date'])-1):\n",
    "    if current_positive_dates['date'].iloc[i+1] - pd.DateOffset(days=1) == current_positive_dates['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(current_positive_dates['date'].iloc[current_i], current_positive_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.5)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(current_positive_dates['date'].iloc[current_i], current_positive_dates['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "market_cap.plot(ax=ax2, alpha=0.5, color=\"tab:orange\", label=\"Index Market Cap (Log)\", logy=True, linewidth=2)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "ax2.axes.get_yaxis().set_ticks([])\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.axes.get_xaxis().set_label_text('')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig.savefig(\"../../figures/markov_regression_oos.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot every endog variable separately\n",
    "for name, group in probabilities.groupby('endog'):\n",
    "    plt.figure()\n",
    "    group.plot(x='date', y='p', title=f\"Probabilities for Endog: {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_files = os.listdir(\"../../results/regime/markov_collected/\")\n",
    "save_years = list(range(2020,2020+1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in save_years:\n",
    "    file = [file for file in collected_files if str(year) in file][0]\n",
    "    if \"probabilities\" not in file:\n",
    "        continue\n",
    "    print(file)\n",
    "    current_probabilites = pd.read_csv(\"../../results/regime/markov_collected/\" + file)\n",
    "    current_probabilites[\"date\"] = pd.to_datetime(current_probabilites[\"date\"])\n",
    "    if (current_probabilites[\"date\"].dt.day.unique().item() != 1):\n",
    "        print(\"Not centered on MS\")\n",
    "        break\n",
    "    #Recession\n",
    "    avg_probabilities = current_probabilites.groupby(\"date\")[\"p\"].mean()\n",
    "    avg_probabilities = pd.DataFrame(avg_probabilities)\n",
    "    avg_probabilities[\"class\"] = 0\n",
    "    avg_probabilities.loc[avg_probabilities[avg_probabilities[\"p\"] > avg_probabilities[\"p\"].rolling(f'{5*12*30}D').mean()].index, \"class\"] = 1\n",
    "    avg_probabilities_daily = avg_probabilities.resample(\"D\").ffill()\n",
    "    avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-31\")] = avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-01\")]\n",
    "    avg_probabilities_daily = avg_probabilities_daily.resample(\"D\").ffill()\n",
    "    \n",
    "    pd.DataFrame(avg_probabilities_daily[avg_probabilities_daily[\"class\"] == 1].index, columns=[\"date\"]).to_csv(f\"../../time_periods/model_train_ready_before_test/markov_rec_dates_train_{year}_order1_4_10_smooth_5yr_avg.csv\", index=False)\n",
    "    \n",
    "    #Expansion\n",
    "    expansion_probabilities = current_probabilites.copy()\n",
    "    expansion_probabilities[\"p\"] = 1 - expansion_probabilities[\"p\"]\n",
    "    avg_probabilities = expansion_probabilities.groupby(\"date\")[\"p\"].mean()\n",
    "    avg_probabilities = pd.DataFrame(avg_probabilities)\n",
    "    avg_probabilities[\"class\"] = 0\n",
    "    avg_probabilities.loc[avg_probabilities[avg_probabilities[\"p\"] > avg_probabilities[\"p\"].rolling(f'{5*12*30}D').mean()].index, \"class\"] = 1\n",
    "    avg_probabilities_daily = avg_probabilities.resample(\"D\").ffill()\n",
    "    avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-31\")] = avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-01\")]\n",
    "    avg_probabilities_daily = avg_probabilities_daily.resample(\"D\").ffill()\n",
    "    pd.DataFrame(avg_probabilities_daily[avg_probabilities_daily[\"class\"] == 1].index, columns=[\"date\"]).to_csv(f\"../../time_periods/model_train_ready_before_test/markov_exp_dates_train_{year}_order1_4_10_smooth_5yr_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_probabilites = pd.read_csv(\"../../results/regime/markov_collected/probabilities_scale_win3std_log_test_all_years_order1_4_10.csv\")\n",
    "\n",
    "current_probabilites[\"date\"] = pd.to_datetime(current_probabilites[\"date\"])\n",
    "if (current_probabilites[\"date\"].dt.day.unique().item() != 1):\n",
    "    print(\"Not centered on MS\")\n",
    "else:\n",
    "    #Recession\n",
    "    avg_probabilities = current_probabilites.groupby(\"date\")[\"p\"].mean()\n",
    "    avg_probabilities = pd.DataFrame(avg_probabilities)\n",
    "    avg_probabilities[\"class\"] = 0\n",
    "    avg_probabilities.loc[avg_probabilities[avg_probabilities[\"p\"] > avg_probabilities[\"p\"].rolling(f'{5*12*30}D').mean()].index, \"class\"] = 1\n",
    "    avg_probabilities_daily = avg_probabilities.resample(\"D\").ffill()\n",
    "    avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-31\")] = avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-01\")]\n",
    "    avg_probabilities_daily = avg_probabilities_daily.resample(\"D\").ffill()\n",
    "\n",
    "    pd.DataFrame(avg_probabilities_daily[avg_probabilities_daily[\"class\"] == 1].index, columns=[\"date\"]).to_csv(f\"../../results/regime/markov_test/markov_rec_dates_test_all_years_order1_4_10_5yr_avg.csv\", index=False)\n",
    "\n",
    "    #Expansion\n",
    "    expansion_probabilities = current_probabilites.copy()\n",
    "    expansion_probabilities[\"p\"] = 1 - expansion_probabilities[\"p\"]\n",
    "    avg_probabilities = expansion_probabilities.groupby(\"date\")[\"p\"].mean()\n",
    "    avg_probabilities = pd.DataFrame(avg_probabilities)\n",
    "    avg_probabilities[\"class\"] = 0\n",
    "    avg_probabilities.loc[avg_probabilities[avg_probabilities[\"p\"] > avg_probabilities[\"p\"].rolling(f'{5*12*30}D').mean()].index, \"class\"] = 1\n",
    "    avg_probabilities_daily = avg_probabilities.resample(\"D\").ffill()\n",
    "    avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-31\")] = avg_probabilities_daily.loc[pd.Timestamp(f\"{year-1}-12-01\")]\n",
    "    avg_probabilities_daily = avg_probabilities_daily.resample(\"D\").ffill()\n",
    "    pd.DataFrame(avg_probabilities_daily[avg_probabilities_daily[\"class\"] == 1].index, columns=[\"date\"]).to_csv(f\"../../results/regime/markov_test/markov_exp_dates_test_all_years_order1_4_10_5yr_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
