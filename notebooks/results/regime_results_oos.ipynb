{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, confusion_matrix, r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_parquet(\"../../data/indicators/US/all_indicators_raw_outer.parquet\", engine=\"pyarrow\")\n",
    "indicators[\"date\"] = pd.to_datetime(indicators[\"date\"])\n",
    "indicators.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_recessions = pd.read_parquet(\"../../data/indicators/US/nber_recession.parquet\")\n",
    "nber_recessions[\"date\"] = pd.to_datetime(nber_recessions[\"date\"])\n",
    "nber_recessions = nber_recessions[nber_recessions[\"date\"] >= \"1962-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_top_500 = pd.read_parquet(\"../../data/indicators/US/us_top_500.parquet\", engine=\"pyarrow\")\n",
    "us_top_500[\"date\"] = pd.to_datetime(us_top_500[\"date\"])\n",
    "data = pd.merge(indicators, us_top_500, on=[\"date\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"unemployment_change\"] = data[\"unemployment\"].dropna().pct_change()\n",
    "data[\"initial_claims_change\"] = data[\"initial_claims\"].dropna().pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"trr_w_wed\"] = data[\"market_cap_usd\"].resample(\"W-WED\").last().pct_change()\n",
    "data[\"trr_w_thu\"] = data[\"market_cap_usd\"].resample(\"W-THU\").last().pct_change()\n",
    "data[\"trr_w_fri\"] = data[\"market_cap_usd\"].resample(\"W-FRI\").last().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "markov_date_files = os.listdir(\"../../time_periods/model_train_ready_before_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.Timestamp(\"1962-01-01\")\n",
    "max_date = pd.Timestamp(\"2019-12-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_rec_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_rec_dates[\"date\"] = pd.to_datetime(markov_rec_dates[\"date\"])\n",
    "markov_rec = data.copy()[data.index.isin(markov_rec_dates[\"date\"])]\n",
    "markov_rec[\"name\"] = \"markov_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready/nber_recession_dates.csv\")\n",
    "nber_rec_dates[\"date\"] = pd.to_datetime(nber_rec_dates[\"date\"])\n",
    "nber_rec = data.copy()[data.index.isin(nber_rec_dates[\"date\"])]\n",
    "nber_rec[\"name\"] = \"nber_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_bear_dates = pd.read_csv(\"../../time_periods/model_train_ready/bear_dates_sp500.csv\")\n",
    "sp500_bear_dates[\"date\"] = pd.to_datetime(sp500_bear_dates[\"date\"])\n",
    "sp500_bear = data.copy()[data.index.isin(sp500_bear_dates[\"date\"])]\n",
    "sp500_bear[\"name\"] = \"sp500_bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bear_dates_1 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bear_m_long_3_6_12.csv\")\n",
    "filter_bear_dates_1[\"date\"] = pd.to_datetime(filter_bear_dates_1[\"date\"])\n",
    "filter_bear_1 = data.copy()[data.index.isin(filter_bear_dates_1[\"date\"])]\n",
    "filter_bear_1[\"name\"] = \"filter_bear_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bear_dates_2 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bear_m_short_2_3.csv\")\n",
    "filter_bear_dates_2[\"date\"] = pd.to_datetime(filter_bear_dates_2[\"date\"])\n",
    "filter_bear_2 = data.copy()[data.index.isin(filter_bear_dates_2[\"date\"])]\n",
    "filter_bear_2[\"name\"] = \"filter_bear_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epu_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready/EPU_rec_2yr.csv\")\n",
    "epu_rec_dates[\"date\"] = pd.to_datetime(epu_rec_dates[\"date\"])\n",
    "epu_rec = data.copy()[data.index.isin(epu_rec_dates[\"date\"])]\n",
    "epu_rec[\"name\"] = \"epu_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_exp_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_exp_dates[\"date\"] = pd.to_datetime(markov_exp_dates[\"date\"])\n",
    "markov_exp = data.copy()[data.index.isin(markov_exp_dates[\"date\"])]\n",
    "markov_exp[\"name\"] = \"markov_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready/nber_expansion_dates.csv\")\n",
    "nber_exp_dates[\"date\"] = pd.to_datetime(nber_exp_dates[\"date\"])\n",
    "nber_exp = data.copy()[data.index.isin(nber_exp_dates[\"date\"])]\n",
    "nber_exp[\"name\"] = \"nber_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_bull_dates = pd.read_csv(\"../../time_periods/model_train_ready/bull_dates_sp500.csv\")\n",
    "sp500_bull_dates[\"date\"] = pd.to_datetime(sp500_bull_dates[\"date\"])\n",
    "sp500_bull = data.copy()[data.index.isin(sp500_bull_dates[\"date\"])]\n",
    "sp500_bull[\"name\"] = \"sp500_bull\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_non_bear_dates = pd.read_csv(\"../../time_periods/model_train_ready/non_bear_dates_sp500.csv\")\n",
    "sp500_non_bear_dates[\"date\"] = pd.to_datetime(sp500_non_bear_dates[\"date\"])\n",
    "sp500_non_bear = data.copy()[data.index.isin(sp500_non_bear_dates[\"date\"])]\n",
    "sp500_non_bear[\"name\"] = \"sp500_non_bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bull_dates_1 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bull_m_long_3_6_12.csv\")\n",
    "filter_bull_dates_1[\"date\"] = pd.to_datetime(filter_bull_dates_1[\"date\"])\n",
    "filter_bull_1 = data.copy()[data.index.isin(filter_bull_dates_1[\"date\"])]\n",
    "filter_bull_1[\"name\"] = \"filter_bull_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bull_dates_2 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bull_m_short_2_3.csv\")\n",
    "filter_bull_dates_2[\"date\"] = pd.to_datetime(filter_bull_dates_2[\"date\"])\n",
    "filter_bull_2 = data.copy()[data.index.isin(filter_bull_dates_2[\"date\"])]\n",
    "filter_bull_2[\"name\"] = \"filter_bull_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epu_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready/EPU_exp_2yr.csv\")\n",
    "epu_exp_dates[\"date\"] = pd.to_datetime(epu_exp_dates[\"date\"])\n",
    "epu_exp = data.copy()[data.index.isin(epu_exp_dates[\"date\"])]\n",
    "epu_exp[\"name\"] = \"epu_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_flat_dates = pd.read_csv(\"../../time_periods/model_train_ready/flat_dates_sp500.csv\")\n",
    "sp500_flat_dates[\"date\"] = pd.to_datetime(sp500_flat_dates[\"date\"])\n",
    "sp500_flat = data.copy()[data.index.isin(sp500_flat_dates[\"date\"])]\n",
    "sp500_flat[\"name\"] = \"sp500_flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = data.copy()\n",
    "all_dates[\"name\"] = \"all_dates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_periods = pd.concat([markov_rec, nber_rec, sp500_bear, filter_bear_1, filter_bear_2, epu_rec, markov_exp, nber_exp, sp500_bull, sp500_non_bear, filter_bull_1, filter_bull_2, epu_exp, sp500_flat, all_dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_periods[\"trr_1_n_rel\"] = all_periods[\"trr_1_n\"] - all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == \"all_dates\")][\"trr_1_n\"].mean()\n",
    "all_periods[\"trr_w_wed_rel\"] = all_periods[\"trr_w_wed\"] - all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == \"all_dates\")][\"trr_w_wed\"].mean()\n",
    "all_periods[\"trr_w_thu_rel\"] = all_periods[\"trr_w_thu\"] - all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == \"all_dates\")][\"trr_w_thu\"].mean()\n",
    "all_periods[\"trr_w_fri_rel\"] = all_periods[\"trr_w_fri\"] - all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == \"all_dates\")][\"trr_w_fri\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_test_pred_rec_dates = pd.read_csv(\"../../time_periods/model_test_ready/markov_rec_dates_test_all_years_order1_4_10_5yr_avg.csv\")\n",
    "markov_test_pred_rec_dates[\"date\"] = pd.to_datetime(markov_test_pred_rec_dates[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_test_pred_exp_dates = pd.read_csv(\"../../time_periods/model_test_ready/markov_exp_dates_test_all_years_order1_4_10_5yr_avg.csv\")\n",
    "markov_test_pred_exp_dates[\"date\"] = pd.to_datetime(markov_test_pred_exp_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_rec_dates = pd.read_csv(\"../../time_periods/model_test_ready/nber_recession_dates_class_lstm_ba4da75c.csv\")\n",
    "lstm_test_pred_rec_dates[\"date\"] = pd.to_datetime(lstm_test_pred_rec_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_bear_dates = pd.read_csv(\"../../time_periods/model_test_ready/bear_dates_qbear_class_lstm_9046df4a.csv\")\n",
    "lstm_test_pred_bear_dates[\"date\"] = pd.to_datetime(lstm_test_pred_bear_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_bull_dates = pd.read_csv(\"../../time_periods/model_test_ready/bull_dates_qbull_class_lstm_f241ab59.csv\")\n",
    "lstm_test_pred_bull_dates[\"date\"] = pd.to_datetime(lstm_test_pred_bull_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_non_rec_dates = pd.read_csv(\"../../time_periods/model_test_ready/nber_non_recession_dates_class_lstm_ba4da75c.csv\")\n",
    "lstm_test_pred_non_rec_dates[\"date\"] = pd.to_datetime(lstm_test_pred_non_rec_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_mc_change_class_bear = pd.read_csv(\"../../time_periods/model_test_ready/bear_lstm_mc_change_class.csv\")\n",
    "lstm_test_pred_mc_change_class_bear[\"date\"] = pd.to_datetime(lstm_test_pred_mc_change_class_bear[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_pred_mc_change_class_bull = pd.read_csv(\"../../time_periods/model_test_ready/bull_lstm_mc_change_class.csv\")\n",
    "lstm_test_pred_mc_change_class_bull[\"date\"] = pd.to_datetime(lstm_test_pred_mc_change_class_bull[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dirs = os.listdir(\"../../results/regime/lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "\n",
    "recall_scores = {}\n",
    "precision_scores = {}\n",
    "acc_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "print_all = True\n",
    "\n",
    "for directory in result_dirs:\n",
    "    if \"c44a4142\" in directory:\n",
    "        print(directory[-8:])\n",
    "        current_results = pd.read_csv(f\"../../results/regime/lstm/{directory}/test_results.csv\")\n",
    "        recall_scores[directory[-8:]] = recall_score(current_results[\"real_class\"], current_results[\"pred_class\"])\n",
    "        precision_scores[directory[-8:]] = precision_score(current_results[\"real_class\"], current_results[\"pred_class\"])\n",
    "        acc_scores[directory[-8:]] = accuracy_score(current_results[\"real_class\"], current_results[\"pred_class\"])\n",
    "        f1_scores[directory[-8:]] = f1_score(current_results[\"real_class\"], current_results[\"pred_class\"])\n",
    "\n",
    "        if print_all:\n",
    "            with open(f\"../../results/regime/lstm/{directory}/summary.txt\") as f:\n",
    "                print(f.read())\n",
    "                pass\n",
    "            print(confusion_matrix(current_results[\"real_class\"], current_results[\"pred_class\"]))\n",
    "            print(\"Recall\", recall_score(current_results[\"real_class\"], current_results[\"pred_class\"]))\n",
    "            print(\"Precision\", precision_score(current_results[\"real_class\"], current_results[\"pred_class\"]))\n",
    "            print(\"Accuracy\", accuracy_score(current_results[\"real_class\"], current_results[\"pred_class\"]))\n",
    "            print(\"F1\", f1_score(current_results[\"real_class\"], current_results[\"pred_class\"]))\n",
    "            print()\n",
    "            \n",
    "print(\"Recall\")\n",
    "print(max(recall_scores, key=recall_scores.get), recall_scores[max(recall_scores, key=recall_scores.get)])\n",
    "print(\"Precision\")\n",
    "print(max(precision_scores, key=precision_scores.get), precision_scores[max(precision_scores, key=precision_scores.get)])\n",
    "print(\"Accuracy\")\n",
    "print(max(acc_scores, key=acc_scores.get), acc_scores[max(acc_scores, key=acc_scores.get)])\n",
    "print(\"F1\")\n",
    "print(max(f1_scores, key=f1_scores.get), f1_scores[max(f1_scores, key=f1_scores.get)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_change_class_results = pd.read_csv(\"../../results/regime/lstm/mc_change_class_train_before_1980_win_std_3_scale_log_retrained_c44a4142/test_results.csv\")\n",
    "mc_change_class_results[\"date\"] = pd.to_datetime(mc_change_class_results[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dates_bear = [pd.Timestamp(\"1975-04-01\"), pd.Timestamp(\"1983-02-15\"), pd.Timestamp(\"1985-02-01\"), pd.Timestamp(\"1988-06-07\"), \n",
    "                        pd.Timestamp(\"1991-04-10\"), pd.Timestamp(\"1999-04-10\"), pd.Timestamp(\"2000-11-25\"),\n",
    "                        pd.Timestamp(\"2003-09-12\"), pd.Timestamp(\"2009-09-10\"), pd.Timestamp(\"2011-01-10\"),  \n",
    "                        pd.Timestamp(\"2012-04-04\"), pd.Timestamp(\"2016-08-12\"), pd.Timestamp(\"2019-06-28\"), \n",
    "                        #  pd.Timestamp(\"2020-09-28\"), pd.Timestamp(\"2023-04-15\"), pd.Timestamp(\"2024-05-01\"), \n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_dates_bull = [\n",
    "    pd.Timestamp('1976-01-15'), pd.Timestamp('1981-05-26'), pd.Timestamp('1983-12-23'),\n",
    "    pd.Timestamp('1988-02-25'), pd.Timestamp('1990-04-09'), pd.Timestamp('1994-08-01'),\n",
    "    pd.Timestamp('1999-01-17'),pd.Timestamp('2000-09-24'),pd.Timestamp('2004-09-01'),\n",
    "    pd.Timestamp('2005-08-28'),pd.Timestamp('2006-11-08'),pd.Timestamp('2008-01-17'),\n",
    "    pd.Timestamp('2010-10-23'),pd.Timestamp('2011-11-02'),pd.Timestamp('2015-11-19'),\n",
    "    pd.Timestamp('2018-07-25'),pd.Timestamp('2019-03-20'),pd.Timestamp('2020-08-19'),\n",
    "    pd.Timestamp('2022-07-03')\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 4), sharex=False)\n",
    "\n",
    "min_year = 1980\n",
    "max_year = 2023\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "min_date = pd.Timestamp(f\"{min_year}-01-01\")\n",
    "max_date = pd.Timestamp(f\"{max_year}-12-31\")\n",
    "\n",
    "data_display = data_copy[(data_copy.index >= min_date) & (data_copy.index <= max_date)]\n",
    "\n",
    "market_cap = data_display[\"market_cap_usd\"].dropna()\n",
    "\n",
    "market_cap.plot(ax=ax, alpha=0.5, color=\"tab:orange\", label=\"Index Market Cap (Log)\", logy=True, linewidth=2)\n",
    "\n",
    "colors = [\"tab:blue\", \"tab:red\", \"tab:green\", \"tab:orange\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:olive\", \"tab:cyan\"]\n",
    "\n",
    "date_file_true = sp500_bull_dates.copy()\n",
    "\n",
    "date_file_true = date_file_true[date_file_true[\"date\"] >= min_date]\n",
    "date_file_true = date_file_true[date_file_true[\"date\"] <= max_date]\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(date_file_true['date'])-1):\n",
    "    if date_file_true['date'].iloc[i+1] - pd.DateOffset(days=1) == date_file_true['date'].iloc[i]:\n",
    "        continue\n",
    "    print(date_file_true['date'].iloc[current_i], date_file_true['date'].iloc[i] + pd.DateOffset(days=1))\n",
    "    ax.axvspan(date_file_true['date'].iloc[current_i], date_file_true['date'].iloc[i] + pd.DateOffset(days=1), facecolor='tab:brown', alpha=0.5)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(date_file_true['date'].iloc[current_i], date_file_true['date'].iloc[i] + pd.DateOffset(days=1), facecolor='tab:brown', alpha=0.5)\n",
    "\n",
    "\n",
    "current_date_file = lstm_test_pred_mc_change_class_bull.copy()\n",
    "\n",
    "current_date_file = current_date_file[current_date_file[\"date\"] >= min_date]\n",
    "current_date_file = current_date_file[current_date_file[\"date\"] <= max_date]\n",
    "\n",
    "current_i = 0\n",
    "for i in range(len(current_date_file['date'])-1):\n",
    "    if current_date_file['date'].iloc[i+1] - pd.DateOffset(days=1) == current_date_file['date'].iloc[i]:\n",
    "        continue\n",
    "    ax.axvspan(current_date_file['date'].iloc[current_i], current_date_file['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.9)\n",
    "    current_i = i + 1\n",
    "ax.axvspan(current_date_file['date'].iloc[current_i], current_date_file['date'].iloc[i] + pd.DateOffset(days=1), facecolor='blue', alpha=0.3, ymin=0.1, ymax=0.9)\n",
    "\n",
    "\n",
    "axvlines = None\n",
    "\n",
    "if axvlines is not None:\n",
    "    for line in axvlines:\n",
    "        ax.axvline(line, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "\n",
    "nber_start_ann_dates = [\"1980-06-03\", \"1982-01-06\", \"1991-04-25\", \"2001-11-26\", \"2008-12-01\"]\n",
    "\n",
    "plt.xlim(left=min_date, right=max_date)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "ax.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "ax.axes.get_xaxis().set_label_text('')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/LSTM_model_bear_mc_change_timeline.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/LSTM_model_bull_mc_change_timeline.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/LSTM_model_NBER_recessions_timeline.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name_dict = {\n",
    "    'nber_recession_dates_class_lstm_ba4da75c' : \"NBER Recession Class LSTM\",\n",
    "    'nber_non_recession_dates_class_lstm_ba4da75c' : \"NBER Non-Recession Class LSTM\",\n",
    "    'bear_dates_qbear_class_lstm_9046df4a' : \"Bear Class LSTM\",\n",
    "    'bull_dates_qbull_class_lstm_f241ab59' : \"Bull Class LSTM\",\n",
    "    'non_bear_dates_qbear_class_lstm_9046df4a' : \"Non-Bear Class LSTM\",\n",
    "    'non_bull_dates_bqull_class_lstm_f241ab59' : \"Non-Bull Class LSTM\",\n",
    "    'markov_rec_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Recession\",\n",
    "    'markov_exp_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Expansion\",\n",
    "    'bear_lstm_mc_change_class' : \"Bear MC Change LSTM\",\n",
    "    'bull_lstm_mc_change_class' : \"Bull MC Change LSTM\",\n",
    "    'return_filter_bear_m_long_3_6_12' : \"Negative Filter (LT)\",\n",
    "    'return_filter_bear_m_short_2_3' : \"Negative Filter (ST)\",\n",
    "    'return_filter_bull_m_long_3_6_12' : \"Positive Filter (LT)\",\n",
    "    'return_filter_bull_m_short_2_3' : \"Positive Filter (ST)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name_dict_order = {\n",
    "    'nber_recession_dates_class_lstm_ba4da75c' : \"NBER Recession Class LSTM\",\n",
    "    'bear_dates_qbear_class_lstm_9046df4a' : \"Bear Class LSTM\",\n",
    "    'non_bull_dates_bqull_class_lstm_f241ab59' : \"Non-Bull Class LSTM\",\n",
    "    'markov_rec_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Recession\",\n",
    "    'bear_lstm_mc_change_class' : \"Bear MC Change LSTM\",\n",
    "    'return_filter_bear_m_long_3_6_12' : \"Negative Filter (LT)\",\n",
    "    'return_filter_bear_m_short_2_3' : \"Negative Filter (ST)\",\n",
    "    \n",
    "    'nber_non_recession_dates_class_lstm_ba4da75c' : \"NBER Non-Recession Class LSTM\",\n",
    "    'bull_dates_qbull_class_lstm_f241ab59' : \"Bull Class LSTM\",\n",
    "    'non_bear_dates_qbear_class_lstm_9046df4a' : \"Non-Bear Class LSTM\",\n",
    "    'markov_exp_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Expansion\",\n",
    "    'return_filter_bull_m_long_3_6_12' : \"Positive Filter (LT)\",\n",
    "    'return_filter_bull_m_short_2_3' : \"Positive Filter (ST)\",\n",
    "    'bull_lstm_mc_change_class' : \"Bull MC Change LSTM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name_dict = {\n",
    "    'bear_dates_sp500' : \"Qualitative Bear\",\n",
    "    'bull_dates_sp500' : \"Qualitative Bull\",\n",
    "    'nber_recession_dates' : \"NBER Recession\",\n",
    "    'nber_expansion_dates' : \"NBER Expansion\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_files = os.listdir(\"../../time_periods/model_test_ready/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.Timestamp(\"1980-01-01\")\n",
    "max_date = pd.Timestamp(\"2023-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_periods = data.copy()\n",
    "all_test_periods[\"name\"] = \"all_dates\"\n",
    "all_test_periods[\"proper_name\"] = \"All Dates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, test_file in enumerate(all_test_files):\n",
    "    current_dates = pd.read_csv(f\"../../time_periods/model_test_ready/{test_file}\")\n",
    "    current_dates[\"date\"] = pd.to_datetime(current_dates[\"date\"])\n",
    "    current_test_period = data.copy()[data.index.isin(current_dates[\"date\"])]\n",
    "    current_test_period[\"name\"] = test_file.split(\".\")[0]\n",
    "    current_test_period[\"proper_name\"] = test_file_name_dict[test_file.split(\".\")[0]]\n",
    "    all_test_periods = pd.concat([all_test_periods, current_test_period])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, test_file in enumerate([\"bear_dates_sp500.csv\", \"bull_dates_sp500.csv\", \"nber_recession_dates.csv\", \"nber_expansion_dates.csv\"]):\n",
    "    current_dates = pd.read_csv(f\"../../time_periods/model_train_ready/{test_file}\")\n",
    "    current_dates[\"date\"] = pd.to_datetime(current_dates[\"date\"])\n",
    "    current_test_period = data.copy()[data.index.isin(current_dates[\"date\"])]\n",
    "    current_test_period[\"name\"] = test_file.split(\".\")[0]\n",
    "    current_test_period[\"proper_name\"] = train_file_name_dict[test_file.split(\".\")[0]]\n",
    "    all_test_periods = pd.concat([all_test_periods, current_test_period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_periods[\"trr_1_n_rel\"] = all_test_periods[\"trr_1_n\"] - all_test_periods[(all_test_periods.index > min_date) & (all_test_periods.index < max_date) & (all_test_periods[\"name\"] == \"all_dates\")][\"trr_1_n\"].mean()\n",
    "all_test_periods[\"trr_w_fri_rel\"] = all_test_periods[\"trr_w_fri\"] - all_test_periods[(all_test_periods.index > min_date) & (all_test_periods.index < max_date) & (all_test_periods[\"name\"] == \"all_dates\")][\"trr_w_fri\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "\n",
    "min_date = pd.Timestamp(\"1962-01-01\")\n",
    "max_date = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "feature = \"trr_1_n\"\n",
    "\n",
    "\n",
    "order = list(test_file_name_dict_order.keys())\n",
    "labels = list(test_file_name_dict_order.values())\n",
    "\n",
    "for i, name in enumerate(order):\n",
    "    ax.boxplot(all_test_periods[(all_test_periods.index > min_date) & (all_test_periods.index < max_date) & (all_test_periods[\"name\"] == name)][feature].dropna(), positions=[i], labels=[labels[i]],\n",
    "               widths=0.5, showfliers=False, showmeans=True, meanline=True,\n",
    "               whiskerprops={\"color\": \"tab:blue\", 'lw' : 2}, flierprops={\"color\": \"tab:blue\", 'lw' : 2}, boxprops={\"color\": \"tab:blue\", 'lw' : 2}, \n",
    "               medianprops={\"color\": \"tab:orange\", 'lw' : 2}, capprops={\"color\": \"tab:blue\", 'lw' : 2}, meanprops={'lw' : 2})\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "#ax.set_ylim(-0.05, 0.05)\n",
    "plt.tight_layout()\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_boxplot_unemployment_change_with_outliers.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_boxplot_trr_1_n_rel_no_outliers.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name_dict_order = {\n",
    "    'nber_recession_dates_class_lstm_ba4da75c' : \"NBER Recession Class LSTM\",\n",
    "    'bear_dates_qbear_class_lstm_9046df4a' : \"Bear Class LSTM\",\n",
    "    'non_bull_dates_bqull_class_lstm_f241ab59' : \"Non-Bull Class LSTM\",\n",
    "    'markov_rec_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Recession\",\n",
    "    'bear_lstm_mc_change_class' : \"Bear MC Change LSTM\",\n",
    "    'return_filter_bear_m_long_3_6_12' : \"Negative Filter (LT)\",\n",
    "    'return_filter_bear_m_short_2_3' : \"Negative Filter (ST)\",\n",
    "    \n",
    "    'nber_non_recession_dates_class_lstm_ba4da75c' : \"NBER Non-Recession Class LSTM\",\n",
    "    'bull_dates_qbull_class_lstm_f241ab59' : \"Bull Class LSTM\",\n",
    "    'non_bear_dates_qbear_class_lstm_9046df4a' : \"Non-Bear Class LSTM\",\n",
    "    'markov_exp_dates_test_all_years_order1_4_10_5yr_avg' : \"Markov Expansion\",\n",
    "    'return_filter_bull_m_long_3_6_12' : \"Positive Filter (LT)\",\n",
    "    'return_filter_bull_m_short_2_3' : \"Positive Filter (ST)\",\n",
    "    'bull_lstm_mc_change_class' : \"Bull MC Change LSTM\",\n",
    "\n",
    "     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(18,8))\n",
    "\n",
    "min_date = pd.Timestamp(\"1980-01-01\")\n",
    "max_date = pd.Timestamp(\"2023-12-31\")\n",
    "\n",
    "feature = \"trr_w_fri_rel\"\n",
    "\n",
    "#all_periods_current = all_test_periods.copy()[all_test_periods[\"initial_claims_change\"] < 1]\n",
    "#all_periods_current = all_test_periods.copy()[all_test_periods[\"trr_w_fri_rel\"] < 1]\n",
    "#all_periods_current = all_test_periods.copy()[all_test_periods[\"trr_w_fri_rel\"] > -0.5]\n",
    "\n",
    "all_periods_current = all_test_periods.copy()\n",
    "\n",
    "order = list(test_file_name_dict_order.keys())\n",
    "labels = list(test_file_name_dict_order.values())\n",
    "\n",
    "\n",
    "\n",
    "for i, name in enumerate(order):\n",
    "    hatch = None\n",
    "    if \"bear\" in name or \"rec\" in name or \"non_bull\" in name:\n",
    "        if \"non_bear\" not in name and \"non_rec\" not in name:\n",
    "            hatch = \"\\\\\\\\\"\n",
    "    if \"flat\" in name or \"all_dates\" in name:\n",
    "        hatch = '..'\n",
    "    if i == 0:\n",
    "        bar1 = ax.bar(height = all_periods_current[(all_periods_current.index > min_date) & (all_periods_current.index < max_date) & (all_periods_current[\"name\"] == name)][feature].dropna().mean(), \n",
    "           x=i-0.2, width=0.4, label=\"Mean\", color=\"tab:blue\", edgecolor=\"black\", hatch=hatch)\n",
    "        bar2 = ax.bar(height = all_periods_current[(all_periods_current.index > min_date) & (all_periods_current.index < max_date) & (all_periods_current[\"name\"] == name)][feature].dropna().median(), \n",
    "           x=i+0.2, width=0.4, label=\"Median\", color=\"tab:orange\", edgecolor=\"black\", hatch=hatch)\n",
    "    else:\n",
    "        bar1 = ax.bar(height = all_periods_current[(all_periods_current.index > min_date) & (all_periods_current.index < max_date) & (all_periods_current[\"name\"] == name)][feature].dropna().mean(), \n",
    "            x=i-0.2, width=0.4, color=\"tab:blue\", edgecolor=\"black\", hatch=hatch)\n",
    "        bar2 = ax.bar(height = all_periods_current[(all_periods_current.index > min_date) & (all_periods_current.index < max_date) & (all_periods_current[\"name\"] == name)][feature].dropna().median(), \n",
    "            x=i+0.2, width=0.4, color=\"tab:orange\", edgecolor=\"black\", hatch=hatch)\n",
    "        \n",
    "    if all_periods_current[(all_periods_current.index > min_date) & (all_periods_current.index < max_date) & (all_periods_current[\"name\"] == name)][feature].dropna().median() == 0:\n",
    "        ax.bar_label(bar2, padding=3, fontsize=16)\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", lw=1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18, labelbottom=True)\n",
    "plt.xticks(range(0,len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=35, ha='right')\n",
    "\n",
    "ax.grid(axis='y')\n",
    "\n",
    "ax.legend(fontsize=18)\n",
    "leg = ax.get_legend()\n",
    "leg.legend_handles[0].set_hatch(\"\")\n",
    "leg.legend_handles[1].set_hatch(\"\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=2))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two time periods:\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(18,8))\n",
    "\n",
    "min_date_1 = pd.Timestamp(\"1980-01-01\")\n",
    "max_date_1 = pd.Timestamp(\"2002-12-31\")\n",
    "\n",
    "min_date_2 = pd.Timestamp(\"2003-01-01\")\n",
    "max_date_2 = pd.Timestamp(\"2023-12-31\")\n",
    "\n",
    "feature = \"initial_claims_change\"\n",
    "\n",
    "all_periods_current = all_test_periods.copy()[all_test_periods[\"initial_claims_change\"] < 1]\n",
    "\n",
    "#all_periods_current = all_test_periods.copy()\n",
    "\n",
    "order = list(test_file_name_dict_order.keys())# + [\"bear_dates_sp500\", \"bull_dates_sp500\", \"nber_recession_dates\", \"nber_expansion_dates\"]\n",
    "labels = list(test_file_name_dict_order.values())# + [\"Qualitative Bear\", \"Qualitative Bull\", \"NBER Recession\", \"NBER Expansion\"]\n",
    "\n",
    "use_relative = True\n",
    "\n",
    "\n",
    "for i, name in enumerate(order):\n",
    "    hatch = None\n",
    "    if \"bear\" in name or \"rec\" in name or \"non_bull\" in name:\n",
    "        if \"non_bear\" not in name and \"non_rec\" not in name:\n",
    "            hatch = \"\\\\\\\\\"\n",
    "    if \"flat\" in name or \"all_dates\" in name:\n",
    "        hatch = '..'\n",
    "    \n",
    "    if use_relative:\n",
    "        value_1 = all_periods_current[(all_periods_current.index > min_date_1) & (all_periods_current.index < max_date_1) & (all_periods_current[\"name\"] == name)][feature].dropna().mean() - all_periods_current[(all_periods_current.index > min_date_1) & (all_periods_current.index < max_date_1) & (all_periods_current[\"name\"] == \"all_dates\")][feature].dropna().mean()\n",
    "        value_2 = all_periods_current[(all_periods_current.index > min_date_2) & (all_periods_current.index < max_date_2) & (all_periods_current[\"name\"] == name)][feature].dropna().mean() - all_periods_current[(all_periods_current.index > min_date_2) & (all_periods_current.index < max_date_2) & (all_periods_current[\"name\"] == \"all_dates\")][feature].dropna().mean()\n",
    "    else:\n",
    "        value_1 = all_periods_current[(all_periods_current.index > min_date_1) & (all_periods_current.index < max_date_1) & (all_periods_current[\"name\"] == name)][feature].dropna().mean()\n",
    "        value_2 = all_periods_current[(all_periods_current.index > min_date_2) & (all_periods_current.index < max_date_2) & (all_periods_current[\"name\"] == name)][feature].dropna().mean()\n",
    "    \n",
    "    if i == 0:\n",
    "        bar1 = ax.bar(height = value_1, \n",
    "           x=i-0.2, width=0.4, label=\"1980-2002\", color=\"tab:blue\", edgecolor=\"black\", hatch=hatch)\n",
    "        bar2 = ax.bar(height = value_2, \n",
    "           x=i+0.2, width=0.4, label=\"2003-2023\", color=\"tab:orange\", edgecolor=\"black\", hatch=hatch)\n",
    "    else:\n",
    "        bar1 = ax.bar(height = value_1, \n",
    "            x=i-0.2, width=0.4, color=\"tab:blue\", edgecolor=\"black\", hatch=hatch)\n",
    "        bar2 = ax.bar(height = value_2, \n",
    "            x=i+0.2, width=0.4, color=\"tab:orange\", edgecolor=\"black\", hatch=hatch)\n",
    "\n",
    "\n",
    "avg_1 = all_periods_current[(all_periods_current[\"name\"] == \"all_dates\") & (all_periods_current.index > min_date_1) & (all_periods_current.index < max_date_1)][feature].dropna().mean()\n",
    "avg_2 = all_periods_current[(all_periods_current[\"name\"] == \"all_dates\") & (all_periods_current.index > min_date_2) & (all_periods_current.index < max_date_2)][feature].dropna().mean()\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", lw=1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18, labelbottom=True)\n",
    "plt.xticks(range(0,len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=35, ha='right')\n",
    "\n",
    "ax.grid(axis='y')\n",
    "\n",
    "ax.legend(fontsize=18)\n",
    "leg = ax.get_legend()\n",
    "leg.legend_handles[0].set_hatch(\"\")\n",
    "leg.legend_handles[1].set_hatch(\"\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=2))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/test_periods_barplot_trr_w_fri_rel.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/test_periods_barplot_trr_w_fri_rel_time_period_comparison.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/test_periods_barplot_initial_claims_relative_change_time_period_comparison.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pred_dates = filter_bull_dates_2.copy()\n",
    "#current_pred_dates = filter_bull_dates_2.copy()\n",
    "#current_true_dates = nber_rec_dates.copy()\n",
    "current_true_dates = sp500_bear_dates.copy()\n",
    "\n",
    "current_min_date = pd.Timestamp(\"1980-01-01\")\n",
    "current_max_date = pd.Timestamp(\"2023-12-31\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(pd.date_range(start=current_min_date, end=current_max_date, freq=\"B\"), columns=[\"date\"])\n",
    "\n",
    "results_df[\"real_class\"] = 0\n",
    "results_df.loc[results_df[\"date\"].isin(current_true_dates[\"date\"]), \"real_class\"] = 1\n",
    "\n",
    "results_df[\"pred_class\"] = 0\n",
    "results_df.loc[results_df[\"date\"].isin(current_pred_dates[\"date\"]), \"pred_class\"] = 1\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(results_df[\"real_class\"], results_df[\"pred_class\"]))\n",
    "print(\"Recall:\", recall_score(results_df[\"real_class\"], results_df[\"pred_class\"]))\n",
    "print(\"Precision:\", precision_score(results_df[\"real_class\"], results_df[\"pred_class\"]))\n",
    "print(\"F1:\", f1_score(results_df[\"real_class\"], results_df[\"pred_class\"]))\n",
    "print(\"b.days chosen:\", len(results_df[results_df[\"pred_class\"] == 1])/len(results_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
