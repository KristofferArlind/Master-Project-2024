{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_parquet(\"../../data/indicators/US/all_indicators_raw_outer.parquet\", engine=\"pyarrow\")\n",
    "indicators[\"date\"] = pd.to_datetime(indicators[\"date\"])\n",
    "indicators.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_recessions = pd.read_parquet(\"../../data/indicators/US/nber_recession.parquet\")\n",
    "nber_recessions[\"date\"] = pd.to_datetime(nber_recessions[\"date\"])\n",
    "nber_recessions = nber_recessions[nber_recessions[\"date\"] >= \"1962-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_top_500 = pd.read_parquet(\"../../data/indicators/US/us_top_500.parquet\", engine=\"pyarrow\")\n",
    "us_top_500[\"date\"] = pd.to_datetime(us_top_500[\"date\"])\n",
    "data = pd.merge(indicators, us_top_500, on=[\"date\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"unemployment_change\"] = data[\"unemployment\"].dropna().pct_change()\n",
    "data[\"initial_claims_change\"] = data[\"initial_claims\"].dropna().pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"trr_w_wed\"] = data[\"market_cap_usd\"].resample(\"W-WED\").last().pct_change()\n",
    "data[\"trr_w_thu\"] = data[\"market_cap_usd\"].resample(\"W-THU\").last().pct_change()\n",
    "data[\"trr_w_fri\"] = data[\"market_cap_usd\"].resample(\"W-FRI\").last().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "markov_date_files = os.listdir(\"../../time_periods/model_train_ready_before_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.Timestamp(\"1962-01-01\")\n",
    "max_date = pd.Timestamp(\"2019-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_rec_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_rec_dates[\"date\"] = pd.to_datetime(markov_rec_dates[\"date\"])\n",
    "markov_rec = data.copy()[data.index.isin(markov_rec_dates[\"date\"])]\n",
    "markov_rec[\"name\"] = \"markov_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready/nber_recession_dates.csv\")\n",
    "nber_rec_dates[\"date\"] = pd.to_datetime(nber_rec_dates[\"date\"])\n",
    "nber_rec = data.copy()[data.index.isin(nber_rec_dates[\"date\"])]\n",
    "nber_rec[\"name\"] = \"nber_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_bear_dates = pd.read_csv(\"../../time_periods/model_train_ready/bear_dates_sp500.csv\")\n",
    "sp500_bear_dates[\"date\"] = pd.to_datetime(sp500_bear_dates[\"date\"])\n",
    "sp500_bear = data.copy()[data.index.isin(sp500_bear_dates[\"date\"])]\n",
    "sp500_bear[\"name\"] = \"sp500_bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bear_dates_1 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bear_m_long_3_6_12.csv\")\n",
    "filter_bear_dates_1[\"date\"] = pd.to_datetime(filter_bear_dates_1[\"date\"])\n",
    "filter_bear_1 = data.copy()[data.index.isin(filter_bear_dates_1[\"date\"])]\n",
    "filter_bear_1[\"name\"] = \"filter_bear_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bear_dates_2 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bear_m_short_2_3.csv\")\n",
    "filter_bear_dates_2[\"date\"] = pd.to_datetime(filter_bear_dates_2[\"date\"])\n",
    "filter_bear_2 = data.copy()[data.index.isin(filter_bear_dates_2[\"date\"])]\n",
    "filter_bear_2[\"name\"] = \"filter_bear_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epu_rec_dates = pd.read_csv(\"../../time_periods/model_train_ready/EPU_rec_2yr.csv\")\n",
    "epu_rec_dates[\"date\"] = pd.to_datetime(epu_rec_dates[\"date\"])\n",
    "epu_rec = data.copy()[data.index.isin(epu_rec_dates[\"date\"])]\n",
    "epu_rec[\"name\"] = \"epu_rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready_before_test/markov_exp_dates_train_2020_order1_4_10_smooth_5yr_avg.csv\")\n",
    "markov_exp_dates[\"date\"] = pd.to_datetime(markov_exp_dates[\"date\"])\n",
    "markov_exp = data.copy()[data.index.isin(markov_exp_dates[\"date\"])]\n",
    "markov_exp[\"name\"] = \"markov_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nber_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready/nber_expansion_dates.csv\")\n",
    "nber_exp_dates[\"date\"] = pd.to_datetime(nber_exp_dates[\"date\"])\n",
    "nber_exp = data.copy()[data.index.isin(nber_exp_dates[\"date\"])]\n",
    "nber_exp[\"name\"] = \"nber_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_bull_dates = pd.read_csv(\"../../time_periods/model_train_ready/bull_dates_sp500.csv\")\n",
    "sp500_bull_dates[\"date\"] = pd.to_datetime(sp500_bull_dates[\"date\"])\n",
    "sp500_bull = data.copy()[data.index.isin(sp500_bull_dates[\"date\"])]\n",
    "sp500_bull[\"name\"] = \"sp500_bull\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_non_bear_dates = pd.read_csv(\"../../time_periods/model_train_ready/non_bear_dates_sp500.csv\")\n",
    "sp500_non_bear_dates[\"date\"] = pd.to_datetime(sp500_non_bear_dates[\"date\"])\n",
    "sp500_non_bear = data.copy()[data.index.isin(sp500_non_bear_dates[\"date\"])]\n",
    "sp500_non_bear[\"name\"] = \"sp500_non_bear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bull_dates_1 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bull_m_long_3_6_12.csv\")\n",
    "filter_bull_dates_1[\"date\"] = pd.to_datetime(filter_bull_dates_1[\"date\"])\n",
    "filter_bull_1 = data.copy()[data.index.isin(filter_bull_dates_1[\"date\"])]\n",
    "filter_bull_1[\"name\"] = \"filter_bull_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bull_dates_2 = pd.read_csv(\"../../time_periods/model_train_ready/return_filter_bull_m_short_2_3.csv\")\n",
    "filter_bull_dates_2[\"date\"] = pd.to_datetime(filter_bull_dates_2[\"date\"])\n",
    "filter_bull_2 = data.copy()[data.index.isin(filter_bull_dates_2[\"date\"])]\n",
    "filter_bull_2[\"name\"] = \"filter_bull_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epu_exp_dates = pd.read_csv(\"../../time_periods/model_train_ready/EPU_exp_2yr.csv\")\n",
    "epu_exp_dates[\"date\"] = pd.to_datetime(epu_exp_dates[\"date\"])\n",
    "epu_exp = data.copy()[data.index.isin(epu_exp_dates[\"date\"])]\n",
    "epu_exp[\"name\"] = \"epu_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_flat_dates = pd.read_csv(\"../../time_periods/model_train_ready/flat_dates_sp500.csv\")\n",
    "sp500_flat_dates[\"date\"] = pd.to_datetime(sp500_flat_dates[\"date\"])\n",
    "sp500_flat = data.copy()[data.index.isin(sp500_flat_dates[\"date\"])]\n",
    "sp500_flat[\"name\"] = \"sp500_flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = data.copy()\n",
    "all_dates[\"name\"] = \"all_dates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_periods = pd.concat([markov_rec, nber_rec, sp500_bear, filter_bear_1, filter_bear_2, epu_rec, markov_exp, nber_exp, sp500_bull, sp500_non_bear, filter_bull_1, filter_bull_2, epu_exp, sp500_flat, all_dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in all_periods.groupby(\"name\"):\n",
    "    if \"all_dates\" in name:\n",
    "        continue\n",
    "    elif \"epu\" in name:\n",
    "        current_min_date = pd.Timestamp(\"1985-01-01\")\n",
    "        current_max_date = pd.Timestamp(\"2024-03-01\")\n",
    "    elif \"nber\" in name:\n",
    "        current_min_date = pd.Timestamp(\"1962-01-01\")\n",
    "        current_max_date = pd.Timestamp(\"2024-02-29\")\n",
    "    elif \"sp500\" in name:\n",
    "        current_min_date = pd.Timestamp(\"1962-01-01\")\n",
    "        current_max_date = pd.Timestamp(\"2024-03-28\")\n",
    "    elif \"filter\" in name:\n",
    "        current_min_date = pd.Timestamp(\"1962-01-01\")\n",
    "        current_max_date = pd.Timestamp(\"2024-01-31\")\n",
    "    elif \"markov\" in name:\n",
    "        current_min_date = pd.Timestamp(\"1967-05-01\")\n",
    "        current_max_date = pd.Timestamp(\"2019-12-31\")\n",
    "    else:\n",
    "        print(name, \"skipped\")\n",
    "        continue\n",
    "\n",
    "    current_max_date = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "    all_dates_return = all_periods[(all_periods[\"name\"] ==  \"all_dates\") & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date)][\"trr_1_n\"].mean()\n",
    "    print(name, all_dates_return)\n",
    "    all_periods.loc[(all_periods[\"name\"] == name) & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date), \"trr_1_n_rel\"] = group[\"trr_1_n\"] - all_dates_return\n",
    "    all_dates_return = all_periods[(all_periods[\"name\"] ==  \"all_dates\") & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date) & (all_periods.index.dayofweek == 4)][\"trr_w_wed\"].mean()\n",
    "    all_periods.loc[(all_periods[\"name\"] == name) & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date), \"trr_w_wed_rel\"] = group[\"trr_w_wed\"] - all_dates_return\n",
    "    all_dates_return = all_periods[(all_periods[\"name\"] ==  \"all_dates\") & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date) & (all_periods.index.dayofweek == 4)][\"trr_w_thu\"].mean()\n",
    "    all_periods.loc[(all_periods[\"name\"] == name) & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date), \"trr_w_thu_rel\"] = group[\"trr_w_thu\"] - all_dates_return\n",
    "    all_dates_return = all_periods[(all_periods[\"name\"] ==  \"all_dates\") & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date) & (all_periods.index.dayofweek == 4)][\"trr_w_fri\"].mean()\n",
    "    all_periods.loc[(all_periods[\"name\"] == name) & (all_periods.index >= current_min_date) & (all_periods.index <= current_max_date), \"trr_w_fri_rel\"] = group[\"trr_w_fri\"] - all_dates_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "\n",
    "#bw_method = \"scott\"\n",
    "bw_method = 0.8\n",
    "\n",
    "lw = 3\n",
    "\n",
    "feature = \"trr_w_fri\"\n",
    "\n",
    "nber_rec[(nber_rec.index > min_date) & (nber_rec.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"NBER Rec.\", ax=ax, lw=lw)\n",
    "markov_rec[(markov_rec.index > min_date) & (markov_rec.index < max_date)][feature].plot.kde(bw_method=bw_method, label=\"Markov Rec.\", ax=ax, lw=lw)\n",
    "sp500_bear[(sp500_bear.index > min_date) & (sp500_bear.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"S&P500 Bear\", ax=ax, lw=lw)\n",
    "filter_bear_1[(filter_bear_1.index > min_date) & (filter_bear_1.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"Negative Filter (LT)\", ax=ax, lw=lw)\n",
    "epu_rec[(epu_rec.index > min_date) & (epu_rec.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"EPU Rec.\", ax=ax, lw=lw)\n",
    "\n",
    "#filter_bear_2[(filter_bear_2.index > min_date) & (filter_bear_2.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"Return Filter Bear 2\", ax=ax, lw=lw)\n",
    "\n",
    "\n",
    "nber_exp[(nber_exp.index > min_date) & (nber_exp.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"NBER Exp.\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "markov_exp[(markov_exp.index > min_date) & (markov_exp.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"Markov Exp.\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "sp500_bull[(sp500_bull.index > min_date) & (sp500_bull.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"S&P500 Bull\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "sp500_non_bear[(sp500_non_bear.index > min_date) & (sp500_non_bear.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"S&P500 Non-Bear\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "filter_bull_1[(filter_bull_1.index > min_date) & (filter_bull_1.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"Positive Filter (LT)\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "epu_exp[(epu_exp.index > min_date) & (epu_exp.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"EPU Exp.\", linestyle=\"--\", ax=ax, lw=lw)\n",
    "\n",
    "#filter_bull_2[(filter_bull_2.index > min_date) & (filter_bull_2.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"Return Filter Bull 2\", ax=ax, linestyle=\"--\", lw=lw)\n",
    "\n",
    "\n",
    "sp500_flat[(sp500_flat.index > min_date) & (sp500_flat.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"S&P500 Flat\", ax=ax, linestyle=\"dotted\", lw=lw)\n",
    "data[(data.index > min_date) & (data.index < max_date)][feature].plot.density(bw_method=bw_method, label=\"All Dates\", ax=ax, linestyle=\"dotted\", lw=lw)\n",
    "ax.legend(fontsize=18)\n",
    "ax.set_xlim(-0.09, 0.09)\n",
    "ax.axvline(x=0, color=\"black\", linestyle=\"--\")\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.ylabel(\"Density (bw 0.8)\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_kde_trr_1_n.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_kde_trr_w_fri.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "\n",
    "min_date = pd.Timestamp(\"1962-01-01\")\n",
    "max_date = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "feature = \"trr_1_n\"\n",
    "\n",
    "\n",
    "order = ['nber_rec', 'markov_rec', 'sp500_bear', 'filter_bear_1', 'filter_bear_2', 'epu_rec', 'nber_exp', 'markov_exp', 'sp500_bull', 'sp500_non_bear', 'filter_bull_1', 'filter_bull_2', 'epu_exp', 'sp500_flat', \"all_dates\"]\n",
    "labels = ['NBER Rec.', 'Markov Rec.', 'S&P 500 Bear', 'Negative Filter (LT)', 'Negative Filter (ST)', 'EPU Rec.', 'NBER Exp.', 'Markov Exp.', 'S&P500 Bull', 'S&P500 Non-Bear', 'Positive Filter (LT)', 'Positive Filter (ST)', 'EPU Exp.', 'S&P500 Flat', 'All Dates']\n",
    "\n",
    "for i, name in enumerate(order):\n",
    "    ax.boxplot(all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna(), positions=[i], labels=[labels[i]],\n",
    "               widths=0.5, showfliers=False, showmeans=True, meanline=True,\n",
    "               whiskerprops={\"color\": \"tab:blue\", 'lw' : 2}, flierprops={\"color\": \"tab:blue\", 'lw' : 2}, boxprops={\"color\": \"tab:blue\", 'lw' : 2}, \n",
    "               medianprops={\"color\": \"tab:orange\", 'lw' : 2}, capprops={\"color\": \"tab:blue\", 'lw' : 2}, meanprops={'lw' : 2})\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "#ax.set_ylim(-0.05, 0.05)\n",
    "ax.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_boxplot_unemployment_change_with_outliers.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_boxplot_trr_1_n_no_outliers.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_boxplot_trr_w_fri_no_outliers.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "\n",
    "min_date = pd.Timestamp(\"1962-01-01\")\n",
    "max_date = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "feature = \"trr_w_fri\"\n",
    "\n",
    "\n",
    "order = ['nber_rec', 'markov_rec', 'sp500_bear', 'filter_bear_1', 'filter_bear_2', 'epu_rec', 'nber_exp', 'markov_exp', 'sp500_bull', 'sp500_non_bear', 'filter_bull_1', 'filter_bull_2', 'epu_exp', 'sp500_flat', \n",
    "        # \"all_dates\"\n",
    "         ]\n",
    "labels = ['NBER Rec.', 'Markov Rec.', 'S&P 500 Bear', 'Negative Filter (LT)', 'Negative Filter (ST)', 'EPU Rec.', 'NBER Exp.', 'Markov Exp.', 'S&P500 Bull', 'S&P500 Non-Bear', 'Positive Filter (LT)', 'Positive Filter (ST)', 'EPU Exp.', 'S&P500 Flat', \n",
    "         # 'All Dates'\n",
    "          ]\n",
    "for i, name in enumerate(order):\n",
    "    print(name, all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().index.min(), all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().index.max())\n",
    "\n",
    "    if i == 0:\n",
    "        bar1 = ax.bar(height = all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().mean(), \n",
    "           x=i-0.2, width=0.4, label=\"Mean\", color=\"tab:blue\", edgecolor=\"black\")\n",
    "        bar2 = ax.bar(height = all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().median(), \n",
    "           x=i+0.2, width=0.4, label=\"Median\", color=\"tab:orange\", edgecolor=\"black\")\n",
    "    else:\n",
    "        bar1 = ax.bar(height = all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().mean(), \n",
    "            x=i-0.2, width=0.4, color=\"tab:blue\", edgecolor=\"black\")\n",
    "        bar2 = ax.bar(height = all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().median(), \n",
    "            x=i+0.2, width=0.4, color=\"tab:orange\", edgecolor=\"black\")\n",
    "        \n",
    "    if all_periods[(all_periods.index > min_date) & (all_periods.index < max_date) & (all_periods[\"name\"] == name)][feature].dropna().median() == 0:\n",
    "        ax.bar_label(bar2, padding=3, fontsize=16)\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", lw=1)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18, labelbottom=True)\n",
    "plt.xticks(range(0,len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.grid(axis='y')\n",
    "\n",
    "ax.legend(fontsize=18, loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_barplot_trr_1_n_rel.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_barplot_trr_w_fri_rel.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_barplot_initial_claims_change.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_order = ['nber_rec', 'markov_rec', 'sp500_bear', 'filter_bear_1', 'filter_bear_2', 'epu_rec', 'sp500_flat']\n",
    "\n",
    "bear_labels = ['NBER Rec.', 'Markov Rec.', 'S&P 500 Bear', 'Negative Filter (LT)', 'Negative Filter (ST)', 'EPU Rec.', 'S&P500 Flat']\n",
    "\n",
    "bull_order = ['nber_exp', 'markov_exp', 'sp500_bull', 'sp500_non_bear', 'filter_bull_1', 'filter_bull_2', 'epu_exp', 'sp500_flat']\n",
    "\n",
    "bull_labels = ['NBER Exp.', 'Markov Exp.', 'S&P500 Bull', 'S&P500 Non-Bear', 'Positive Filter (LT)', 'Positive Filter (ST)', 'EPU Exp.', 'S&P500 Flat']\n",
    "\n",
    "all_order = ['nber_rec', 'markov_rec', 'sp500_bear', 'filter_bear_1', 'filter_bear_2', 'epu_rec', \n",
    "         'nber_exp', 'markov_exp', 'sp500_bull', 'sp500_non_bear', 'filter_bull_1', 'filter_bull_2', 'epu_exp', 'sp500_flat'\n",
    "         #, \"all_dates\"\n",
    "         ]\n",
    "\n",
    "all_labels = ['NBER Rec.', 'Markov Rec.', 'S&P 500 Bear', 'Negative Filter (LT)', 'Negative Filter (ST)', 'EPU Rec.', \n",
    "             'NBER Exp.', 'Markov Exp.', 'S&P500 Bull', 'S&P500 Non-Bear', 'Positive Filter (LT)', 'Positive Filter (ST)', 'EPU Exp.', 'S&P500 Flat',\n",
    "               #'All Dates'\n",
    "               ]\n",
    "\n",
    "adjust_for_all_dates_overlap = True\n",
    "\n",
    "order = all_order\n",
    "\n",
    "labels = all_labels\n",
    "\n",
    "corr_df = pd.DataFrame(index=labels, columns=labels + [\"All Dates\"])\n",
    "\n",
    "for i, period_1 in enumerate(order):\n",
    "    corr_row = []\n",
    "    for period_2 in order + [\"all_dates\"]:\n",
    "        if period_1 == period_2:\n",
    "            corr_row.append(np.nan)\n",
    "            continue\n",
    "        current_periods = all_periods[all_periods[\"name\"].isin([period_1, period_2])]\n",
    "\n",
    "        current_max_date = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "        if \"all_dates\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"epu\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1985-01-01\")\n",
    "        elif \"nber\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"sp500\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"filter\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"markov\" in period_1:\n",
    "            current_min_date_1 = pd.Timestamp(\"1967-05-01\")\n",
    "        else:\n",
    "            print(period_1, \"skipped\")\n",
    "            continue\n",
    "\n",
    "        if \"all_dates\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"epu\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1985-01-01\")\n",
    "        elif \"nber\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"sp500\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"filter\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1962-01-01\")\n",
    "        elif \"markov\" in period_2:\n",
    "            current_min_date_2 = pd.Timestamp(\"1967-05-01\")\n",
    "        else:\n",
    "            print(period_2, \"skipped\")\n",
    "            continue\n",
    "\n",
    "        current_min_date = max(current_min_date_1, current_min_date_2)\n",
    "\n",
    "        current_all_dates_n = pd.date_range(current_min_date, current_max_date, freq=\"B\").nunique()\n",
    "\n",
    "        current_periods = current_periods[(current_periods.index > current_min_date) & (current_periods.index < current_max_date)]\n",
    "        current_periods = current_periods[current_periods.index.dayofweek < 5]\n",
    "        current_periods_n = current_periods.index.nunique()\n",
    "        current_periods_n_overlap = current_periods[current_periods.index.value_counts() == 2].index.nunique()\n",
    "\n",
    "        if adjust_for_all_dates_overlap and \"all_dates\" not in period_2:\n",
    "            all_dates_periods = all_periods[all_periods[\"name\"].isin([\"all_dates\", period_1])]\n",
    "            all_dates_periods = all_dates_periods[(all_dates_periods.index > current_min_date) & (all_dates_periods.index < current_max_date)]\n",
    "            all_dates_periods = all_dates_periods[all_dates_periods.index.dayofweek < 5]\n",
    "            all_dates_periods_n = all_dates_periods.index.nunique()\n",
    "            all_dates_periods_n_overlap = all_dates_periods[all_dates_periods.index.value_counts() == 2].index.nunique()\n",
    "            print(period_2, all_dates_periods_n, all_dates_periods_n_overlap)\n",
    "            overlap = float(current_periods_n_overlap/current_periods_n)/float(all_dates_periods_n_overlap/all_dates_periods_n)\n",
    "        else:\n",
    "            overlap = float(current_periods_n_overlap/current_periods_n)\n",
    "\n",
    "        corr_row.append(overlap)\n",
    "    corr_df.loc[labels[i]] = corr_row \n",
    "corr_df = corr_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,9))\n",
    "\n",
    "ax = sb.heatmap(corr_df, cmap=\"flare\", annot=True, cbar=False, square=True, annot_kws={\"fontsize\": 10}\n",
    "                , fmt='.2f'\n",
    "                )\n",
    "ax.set_xticklabels(labels + [\"All Dates\"], rotation=45, ha='right')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16, labelbottom=True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_mean = corr_df.iloc[:-1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_mean.iloc[:,0]  =np.nan\n",
    "corr_df_mean.iloc[1:,1]  =np.nan\n",
    "corr_df_mean.iloc[2:,2]  =np.nan\n",
    "corr_df_mean.iloc[3:,3]  =np.nan\n",
    "corr_df_mean.iloc[4:,4]  =np.nan\n",
    "corr_df_mean.iloc[5:,5]  =np.nan\n",
    "corr_df_mean.iloc[6:,6]  =np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_mean.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_all_periods_corr.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_bear_periods_corr.pdf\", dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../figures/train_periods_bull_periods_corr.pdf\", dpi=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
